<!doctype html>
<html lang="ko">
<head>
<meta charset="utf-8" />
<meta name="viewport" content="width=device-width,initial-scale=1" />
<title>ì£¼ì°¨ ì°¨ëŸ‰ í™•ì¸ê¸° - ê°œì„ íŒ (ìˆ˜ì •ë³¸)</title>
<style>
body { font-family: Arial, sans-serif; padding:20px; background:#f9fafb; text-align:center;}
input{font-size:1.6rem;padding:10px;width:170px;border-radius:8px}
button{font-size:1.2rem;padding:10px 14px;border-radius:8px;background:#2b4eff;color:#fff;border:none;margin:6px}
#status{margin-top:10px;font-weight:600}
table{margin:20px auto;border-collapse:collapse;width:90%;display:none}
th,td{border:1px solid #ddd;padding:12px;background:white}
#debug {font-family:monospace; font-size:12px; text-align:left; max-height:140px; overflow:auto; background:#222; color:#dff; padding:8px; border-radius:6px; margin-top:12px;}
</style>
</head>
<body>
<h2>ğŸ¤ ì£¼ì°¨ ì°¨ëŸ‰ í™•ì¸ê¸° â€” ìˆ˜ì •ë³¸</h2>

<input id="carInput" placeholder="4ìë¦¬ ë²ˆí˜¸" />
<br/>
<button id="checkBtn">ì¡°íšŒ</button>
<button id="voiceBtn">ğŸ™ï¸ ìŒì„±ìœ¼ë¡œ ì¡°íšŒ</button>
<button id="stopVoiceBtn">â–  ì¤‘ì§€</button>
<div id="status"></div>

<table id="resultTable"><thead><tr><th>ë²ˆí˜¸</th><th>ìƒ‰ìƒ</th><th>ì°¨ì¢…</th><th>ì£¼ì°¨ìŠ¤í‹°ì»¤</th></tr></thead><tbody></tbody></table>

<div id="debug" aria-hidden="true"></div>

<script>
/* ì‘ì€ ë°ì´í„° ì˜ˆì‹œ (ì›ë³¸ì— ë§ê²Œ ëŒ€ì²´í•˜ì„¸ìš”) */
const carData = [ { ë²ˆí˜¸:"0114", ì£¼ì°¨ìŠ¤í‹°ì»¤:"ìˆìŒ(í™©ìƒ‰)", ìƒ‰ìƒ:"í°ìƒ‰", ì°¨ì¢…:"ë ˆì´" }, {ë²ˆí˜¸:"1234", ì£¼ì°¨ìŠ¤í‹°ì»¤:"ì—†ìŒ", ìƒ‰ìƒ:"ê²€ì •", ì°¨ì¢…:"ì†Œë‚˜íƒ€"} ];

const inputEl = document.getElementById('carInput');
const statusEl = document.getElementById('status');
const table = document.getElementById('resultTable');
const tbody = table.querySelector('tbody');
const checkBtn = document.getElementById('checkBtn');
const voiceBtn = document.getElementById('voiceBtn');
const stopVoiceBtn = document.getElementById('stopVoiceBtn');
const debugEl = document.getElementById('debug');

let mediaStream = null;
let recognition = null;
let audioContext = null;
let lastStartAt = 0;
let restartAttempts = 0;
const MAX_RESTARTS = 3;
let startedFlag = false; // onstart fired
let stoppedByUser = false;

function logDebug(...args){
  const t = new Date().toISOString();
  debugEl.textContent = t + '  ' + args.map(a=> (typeof a==='object'? JSON.stringify(a): String(a))).join(' ') + '\n' + debugEl.textContent;
}

function showResult(d){
  tbody.innerHTML = `<tr><td>${d.ë²ˆí˜¸}</td><td>${d.ìƒ‰ìƒ}</td><td>${d.ì°¨ì¢…}</td><td>${d.ì£¼ì°¨ìŠ¤í‹°ì»¤}</td></tr>`;
  table.style.display = 'table';
  statusEl.textContent = 'âœ… ì°¨ëŸ‰ ì •ë³´ê°€ í™•ì¸ë˜ì—ˆìŠµë‹ˆë‹¤.';
}

async function playText(text){
  try {
    if(!audioContext){ audioContext = new (window.AudioContext || window.webkitAudioContext)(); }
    if(audioContext.state === 'suspended'){ await audioContext.resume(); }
  } catch(e){ console.warn('AudioContext resume ì‹¤íŒ¨', e); }

  try {
    const u = new SpeechSynthesisUtterance(text);
    u.lang = 'ko-KR';
    speechSynthesis.cancel();
    speechSynthesis.speak(u);
  } catch(e){
    console.warn('speechSynthesis ì‹¤íŒ¨', e);
  }
}

function checkCar(){
  const num = inputEl.value.replace(/\D/g,'').padStart(4,'0');
  if(!num){ playText('ë²ˆí˜¸ë¥¼ ì…ë ¥í•˜ê±°ë‚˜ ë§ì”€í•´ì£¼ì„¸ìš”.'); statusEl.textContent='ë²ˆí˜¸ë¥¼ ì…ë ¥í•˜ì„¸ìš”.'; return; }
  const found = carData.find(c=>c.ë²ˆí˜¸===num);
  if(found){
    showResult(found);
    playText(`${num}ë²ˆ ì°¨ëŸ‰ì€ ${found.ìƒ‰ìƒ} ${found.ì°¨ì¢…}, ì£¼ì°¨ìŠ¤í‹°ì»¤ ${found.ì£¼ì°¨ìŠ¤í‹°ì»¤} ì…ë‹ˆë‹¤.`);
  } else {
    table.style.display='none';
    statusEl.textContent = `ğŸš« ${num}ë²ˆ ì°¨ëŸ‰ ë¯¸ë“±ë¡`;
    playText(`${num}ë²ˆ ì°¨ëŸ‰ì€ ë“±ë¡ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.`);
  }
}

async function ensureMic(){
  if(mediaStream) return mediaStream;
  try {
    mediaStream = await navigator.mediaDevices.getUserMedia({ audio: true });
    statusEl.textContent = 'ğŸ”´ ë§ˆì´í¬ ê¶Œí•œ í—ˆìš©ë¨';
    logDebug('getUserMedia OK');
    return mediaStream;
  } catch(e){
    statusEl.textContent = 'âŒ ë§ˆì´í¬ ê¶Œí•œ í•„ìš”: ì„¤ì •ì—ì„œ í—ˆìš©í•˜ì„¸ìš”.';
    logDebug('getUserMedia fail', e);
    throw e;
  }
}

function stopRecognition(){
  stoppedByUser = true;
  restartAttempts = 0;
  if(recognition){
    try { recognition.onend = ()=>{}; recognition.stop(); } catch(e){ console.warn(e); }
    recognition = null;
  }
  statusEl.textContent = 'ìŒì„± ì¸ì‹ ì¤‘ì§€ë¨';
  logDebug('User stopped recognition');
}

/* ì•ˆì „í•œ TTS unlock: play tiny silent buffer to unlock audio on some devices */
async function unlockAudio(){
  try {
    if(!audioContext) audioContext = new (window.AudioContext || window.webkitAudioContext)();
    if(audioContext.state === 'suspended') await audioContext.resume();
    const buffer = audioContext.createBuffer(1, 1, 22050);
    const src = audioContext.createBufferSource();
    src.buffer = buffer;
    src.connect(audioContext.destination);
    src.start(0);
    logDebug('AudioContext unlocked');
  } catch(e){ logDebug('unlockAudio err', e); }
}

/* Improved startVoice with diagnostics and restart-on-abort logic */
async function startVoice(){
  stoppedByUser = false;
  restartAttempts = 0;
  await unlockAudio(); // ensure audio unlocked from user gesture
  try {
    await ensureMic();
  } catch(e){ return; }

  if(!('webkitSpeechRecognition' in window)){
    alert('ë¸Œë¼ìš°ì €ê°€ Web Speech APIë¥¼ ì§€ì›í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. Chrome ì‚¬ìš© ê¶Œì¥.');
    return;
  }

  // inner function to create and start recognition
  const createAndStart = ()=>{
    if(stoppedByUser) return;
    recognition = new webkitSpeechRecognition();
    recognition.lang = 'ko-KR';
    recognition.interimResults = false;
    recognition.maxAlternatives = 1;
    recognition.continuous = false; // for short phrases, false is more stable on mobile

    startedFlag = false;
    recognition.onstart = ()=> {
      startedFlag = true;
      lastStartAt = Date.now();
      statusEl.textContent = 'ğŸ™ï¸ ë²ˆí˜¸ë¥¼ ë§ì”€í•´ì£¼ì„¸ìš”...';
      logDebug('recognition onstart');
    };

    recognition.onresult = (e) => {
      logDebug('onresult', e);
      const transcript = e.results[0][0].transcript;
      const num = transcript.replace(/[^0-9]/g,'');
      logDebug('transcript ->', transcript, 'digits:', num);
      if(num.length>=2 && num.length<=4){
        inputEl.value = num;
        checkCar();
      } else {
        statusEl.textContent = `âš ï¸ ì¸ì‹ ì‹¤íŒ¨("${transcript}"). ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.`;
        playText('ë²ˆí˜¸ë¥¼ ë‹¤ì‹œ ë§ì”€í•´ì£¼ì„¸ìš”.');
      }
    };

    recognition.onerror = (ev) => {
      logDebug('onerror', ev);
      // handle permission or service errors
      if(ev.error === 'not-allowed' || ev.error === 'service-not-allowed'){
        statusEl.textContent = 'ë§ˆì´í¬ ê¶Œí•œ ë˜ëŠ” ë³´ì•ˆ ë¬¸ì œ. ì„¤ì • í™•ì¸ í•„ìš”.';
        playText('ë§ˆì´í¬ ê¶Œí•œì„ í—ˆìš©í•´ ì£¼ì„¸ìš”.');
      } else {
        // other errors we can attempt a retry
        statusEl.textContent = 'ìŒì„± ì¸ì‹ ì˜¤ë¥˜ ë°œìƒ. ì ì‹œ í›„ ì¬ì‹œë„í•©ë‹ˆë‹¤.';
      }
    };

    recognition.onend = () => {
      logDebug('onend (startedFlag=' + startedFlag + ', attempts=' + restartAttempts + ')');
      recognition = null;
      if(stoppedByUser){
        statusEl.textContent = 'ìŒì„± ì¸ì‹ ì¤‘ì§€ë¨';
        return;
      }
      // If onstart fired and no result within short time, we consider a silent abort and attempt limited restarts.
      const since = Date.now() - lastStartAt;
      if(!startedFlag || (since < 2000 && restartAttempts < MAX_RESTARTS)){
        // quick abort: restart
        restartAttempts++;
        logDebug('Quick abort detected. Restarting recognition, attempt', restartAttempts);
        setTimeout(()=> {
          if(!stoppedByUser) createAndStart();
        }, 300);
      } else {
        statusEl.textContent = 'ìŒì„± ì¸ì‹ì´ ì¢…ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.';
        logDebug('Final end');
      }
    };

    try {
      recognition.start();
      logDebug('recognition.start() called');
    } catch(e){
      logDebug('recognition.start exception', e);
      statusEl.textContent = 'ìŒì„± ì¸ì‹ ì‹œì‘ ì‹¤íŒ¨';
    }
  };

  createAndStart();
}

/* Event binding */
checkBtn.addEventListener('click', (e)=>{ playText('ì¡°íšŒí•©ë‹ˆë‹¤.'); checkCar(); });
voiceBtn.addEventListener('click', async ()=>{ 
  // must be user gesture to unlock audio and to request getUserMedia
  try { await ensureMic(); } catch(e){ return; }
  startVoice();
});
stopVoiceBtn.addEventListener('click', ()=> stopRecognition());

inputEl.addEventListener('keydown', (e)=>{ if(e.key==='Enter') checkCar(); });

/* Debug helper: show browser support info */
(function showEnv(){
  logDebug('UserAgent:' + navigator.userAgent);
  logDebug('webkitSpeechRecognition' in window ? 'SpeechRec OK' : 'SpeechRec NOT AVAILABLE');
  logDebug('HTTPS:' + (location.protocol === 'https:'));
})();
</script>
</body>
</html>
